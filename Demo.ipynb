{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CC4MCSLAEnriched\n",
    "\n",
    "In this notebook, we present our approach implementation. Our approach is based on three components, first the annotation, second the abstraction and last the Checker. \n",
    "\n",
    "## Annotation ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the ontology using owlready2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n"
     ]
    }
   ],
   "source": [
    "from owlready2 import * \n",
    "onto = get_ontology('http://test.org/onto.owl')\n",
    "\n",
    "##### Ontology Definition #####\n",
    "with onto: \n",
    "    class stateMachine(Thing):\n",
    "        pass\n",
    "    class State(stateMachine):\n",
    "        pass\n",
    "    class Start(State):\n",
    "        pass\n",
    "    class Execute(State):\n",
    "        pass\n",
    "    class Complete(State):\n",
    "        pass\n",
    "    class Transition(stateMachine):\n",
    "        pass\n",
    "    class eventType(Thing):\n",
    "        pass\n",
    "    class isRelatedTo(ObjectProperty, FunctionalProperty):\n",
    "        domain = [eventType]\n",
    "        range  = [stateMachine]\n",
    "\n",
    "##### Declare event types\n",
    "Service_Create = eventType('Service_Create', isRelatedTo=Start)\n",
    "Service_Remove = eventType('Service_Remove', isRelatedTo=Start)\n",
    "Service_Update = eventType('Service_Update', isRelatedTo=Start)\n",
    "Container_Create = eventType('Container_Create', isRelatedTo=Execute)\n",
    "Container_Destroy = eventType('Container_Destroy', isRelatedTo=Execute)\n",
    "Container_Start = eventType('Container_Start', isRelatedTo=Complete)\n",
    "Container_Stop = eventType('Container_Stop', isRelatedTo=Complete)\n",
    "Ressource_Usage = eventType('Ressource_Usage', isRelatedTo=Transition)\n",
    "\n",
    "onto.save(file='onto.owl', format=\"rdfxml\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define a function for finding ancestors of indentified event type in event logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Ancestors Calling #####\n",
    "def search_ancestors(onto, ask):\n",
    "    result = onto.search(iri = \"*{}\".format(ask))\n",
    "    lcStep = str(result[0].isRelatedTo).split('.')[1]\n",
    "    smElt = str(result[0].isRelatedTo.is_a[0]).split('.')[1]\n",
    "    if lcStep == 'Transition':\n",
    "        smElt = 'Transition'\n",
    "        lcStep = 'N/A'\n",
    "    return [smElt, lcStep]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we implement the annotation function of xes format adding the state-machine element and lifecycle step for each event and return an xes file with the annotated events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Pre-processing based on ontology ####\n",
    "import pandas as pd\n",
    "import pm4py\n",
    "\n",
    "#### Import event-logs from\n",
    "dataframe = pd.read_csv('logs.csv', sep=',')\n",
    "dataframe = pm4py.format_dataframe(dataframe, case_id='Resource Name', activity_key='Event-Type', timestamp_key='Timestamp')\n",
    "\n",
    "#### Iterate through event logs ####\n",
    "for idx, row in dataframe.iterrows():\n",
    "    # Search event type in ontology and returns ancestors \n",
    "    smElt, lcStep = search_ancestors(onto, row['Event-Type'])\n",
    "    dataframe.loc[[idx],'smElt'] = smElt\n",
    "    dataframe.loc[[idx],'lcStep'] = lcStep\n",
    "\n",
    "### Export as XES ###\n",
    "event_log = pm4py.convert_to_event_log(dataframe)\n",
    "xes = pm4py.write_xes(event_log, 'exported.xes')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstraction\n",
    "\n",
    "Based on the annotated event logs, we abstract state-machine using our defined patterns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List\n",
    "from StateMachine import StateMachine\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "def pattern_identification(log: pd.DataFrame, pattern: List, attribute: str):\n",
    "    \"\"\" \n",
    "        Return index of pattern in log in DataFrame \n",
    "        To Do: \n",
    "            - Add functionnalities to define patterns across several attributes\n",
    "            - Enabled possibilities of eventually follows pattern and several states\n",
    "    \"\"\"\n",
    "    # Identify number of item in pattern\n",
    "    nbPattern = len(pattern)\n",
    "\n",
    "    # Construction pattern as string\n",
    "    ## Begin of request\n",
    "    pattern_s = f\"\"\"log.index[(log['{attribute}'] == '{pattern[0]}')\"\"\"\n",
    "    for item in range(1, nbPattern):\n",
    "        pattern_s += f\"\"\" & (log['{attribute}'].shift(-{item}) == '{pattern[item]}')\"\"\"\n",
    "    ## End of request\n",
    "    pattern_s += f\"\"\"]\"\"\"\n",
    "\n",
    "    # Execution of defined pattern\n",
    "    indice_p_s = eval(pattern_s)\n",
    "    return indice_p_s\n",
    "\n",
    "def state_abstraction(log: pd.DataFrame):\n",
    "    \"\"\"\n",
    "        Return states identified\n",
    "    \"\"\"\n",
    "    ## Declare discovered state machine\n",
    "    SM_Discovered = StateMachine(\n",
    "        name=''\n",
    "    )\n",
    "    pattern=['Start', 'Execute', 'Complete']\n",
    "\n",
    "    states_index = pattern_identification(log, pattern, 'lcStep')\n",
    "    states_name = []\n",
    "\n",
    "    for i, s in enumerate(states_index, 1):\n",
    "        S_name = 'S'+str(i)\n",
    "        states_name.append(S_name)\n",
    "        SM_Discovered.add_state(StateMachine.state(\n",
    "            name= S_name,\n",
    "            type='',\n",
    "            Resourcerequirements={\n",
    "                log.loc[s]['Metric'] : log.loc[s]['Value']\n",
    "            }\n",
    "        ))\n",
    "    return SM_Discovered, states_index, states_name\n",
    "\n",
    "def state_type_abstraction(log: pd.DataFrame, State_Machine_Discovered: StateMachine):\n",
    "    \"\"\"\n",
    "        Apply State-Type Abstraction\n",
    "    \"\"\"\n",
    "    state_nb = len(State_Machine_Discovered.states)\n",
    "    for state in State_Machine_Discovered.states:\n",
    "        if state.name == 'S1':\n",
    "            state.set_type('isInitial')\n",
    "        elif int(state.name[1:]) < state_nb:\n",
    "            state.set_type('isNormal')\n",
    "        elif int(state.name[1:]) == state_nb:\n",
    "            state.set_type('isFinal')\n",
    "    return State_Machine_Discovered\n",
    "\n",
    "def transition_abstraction(log: pd.DataFrame, State_Machine_Discovered: StateMachine, states_index):\n",
    "    \"\"\"\n",
    "        Abstraction transition by combining reconfiguration actions and triggering event associated to the state-machine\n",
    "\n",
    "    \"\"\"\n",
    "    states = State_Machine_Discovered.states\n",
    "    for idx, state in enumerate(states):\n",
    "        if idx < (len(states) - 1):\n",
    "            diff_state = int(states[idx+1].Resourcerequirements['replicas']) - int(states[idx].Resourcerequirements['replicas'])\n",
    "\n",
    "            if diff_state > 0:\n",
    "                type = 'Scale-out'\n",
    "            elif diff_state < 0:\n",
    "                type = 'Scale-in'\n",
    "            else:\n",
    "                type = 'Error'\n",
    "                print('Error: State Equivalent')\n",
    "\n",
    "            #### Get states Event\n",
    "            # Set time window selected\n",
    "            time_window = timedelta(minutes=1)\n",
    "\n",
    "            # Select events in the time window before state execution\n",
    "            pattern_ts = log.loc[states_index[idx+1]]['time:timestamp']\n",
    "            pattern_ts_minus_tw = (pattern_ts - time_window).isoformat()\n",
    "            transition_Window = log[ ( log['time:timestamp'] > pattern_ts_minus_tw) & \\\n",
    "                (log['time:timestamp'] < pattern_ts) & (log['smElt'] == 'Transition' )].astype({'Value': int})\n",
    "            \n",
    "            # Return for each metric observed a consumption average\n",
    "            avg = transition_Window.groupby('Metric')['Value'].mean().to_dict()\n",
    "\n",
    "            if bool(avg) != False:\n",
    "                State_Machine_Discovered.add_transition(\n",
    "                    StateMachine.transition(\n",
    "                        name=f\"T{idx+1}\",\n",
    "                        source=state.name,\n",
    "                        target=states[idx+1].name,\n",
    "                        events=[StateMachine.event(\n",
    "                                    id = 'E1',\n",
    "                                    type = 'ResourceRelatedEvent',\n",
    "                                    predicate = {\n",
    "                                        'metric': 'Cpu Usage',\n",
    "                                        'operator': '>=',\n",
    "                                        'refValue': avg['Cpu Usage'],\n",
    "                                        'time': str(time_window.total_seconds()) + 's'\n",
    "                                    })],\n",
    "                        actions=[StateMachine.action(\n",
    "                            id = 'A1',\n",
    "                            type = type,\n",
    "                            attributes= {\n",
    "                                'replicas' : abs(diff_state)\n",
    "                            }\n",
    "                        )]\n",
    "                ))\n",
    "\n",
    "    return State_Machine_Discovered\n",
    "\n",
    "##### Importation of annotated event logs #####\n",
    "file_path = 'exported.xes'\n",
    "event_log = pm4py.read_xes(file_path)\n",
    "\n",
    "# Filter by case\n",
    "events = event_log.groupby('@@case_index')\n",
    "for i, case_event_log in events:\n",
    "    ##### State abstraction : Pattern 3.1 #####\n",
    "    print(\"State abstraction : Pattern 3.1\")\n",
    "    SM_Discovered, states_index, states_name = state_abstraction(case_event_log)\n",
    "    \n",
    "    ##### State-Type abstraction : Pattern 3.2 #####\n",
    "    print(\"State-Type abstraction : Pattern 3.2\")\n",
    "    SM_Discovered = state_type_abstraction(case_event_log, SM_Discovered)\n",
    "\n",
    "    ##### Transition abstraction : Pattern 3.3 + 3.4 #####\n",
    "    print(\"Transition abstraction : Pattern 3.4\")\n",
    "    SM_Discovered = transition_abstraction(case_event_log, SM_Discovered, states_index)\n",
    "\n",
    "    json = SM_Discovered.to_json()\n",
    "\n",
    "    with open(\"SM_discovered/SM_.json\", \"w\") as outfile:\n",
    "        outfile.write(json)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d1ea9fb40c093137e5631ea40405a634864414780e4b5725c09d6f101604b5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
